---
permalink: /
title: "Welcome"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My mission is to contribute to building AI systems that are Robust. My work in this domain involves combining neural and symbolic representations, out of distribution generalization and stress testing large scale neural models with adversaries. I have been contributing to this direction since 2017. I have broad interest in Deep Learning, Natural Language Processing and Language Grounding (Language+Vision).

Currently I work at [Microsoft Research](https://www.microsoft.com/en-us/research/) as a Senior Researcher, serve as an advisor for [Koidra](https://www.koidra.ai/) and as Associate Editor for IEEE Signal Processing Magazine [Newsletter](https://signalprocessingsociety.org/newsletter). I am a Senior member of [IEEE](https://www.ieee.org/). I have had the priviledge to serve as part of organizing committee of [ACL 2020](https://acl2020.org/) as one of the virtual infrastructure chairs, and to work as a mentor at [Microsoft AI School](https://www.microsoft.com/en-us/ai/ai-school) from 2017 to 2019 and [Microsoft AI Residency Program](https://www.microsoft.com/en-us/research/academic-program/microsoft-ai-residency-program/) from 2019 to 2020.

I have a PhD in Electrical and Computer Engineering from the [University of British Columbia](https://www.ubc.ca/) advised by [Rabab Ward](https://scholar.google.ca/citations?user=dqsw1u8AAAAJ&hl=en) and [Li Deng](https://scholar.google.ca/citations?user=GQWTo4MAAAAJ&hl=en) where I worked on Sparse Decomposition and Compressive Sensing [[1]](https://arxiv.org/abs/1508.04924) and Deep Sentence Representations for Web Search Engines and Information Retrieval [[2]](https://arxiv.org/abs/1502.06922) which recevied IEEE Signal Processing Society Best Paper award in 2019. My MSc and BSc were in Electrical Engineering and I am still an [engineer at heart](https://en.wikipedia.org/wiki/Engineer).


News
------
**[2022](){: .btn--research}** Will be giving a tutorial at [AAAI 2022](https://aaai.org/Conferences/AAAI-22/) on "Neuro-Symbolic Methods for Language and Vision".  
**[2022](){: .btn--research}** Organizing a workshop at [CVPR 2022](https://cvpr2022.thecvf.com/) on "Robustness in Sequential Data".  
**[2022](){: .btn--research}** I have conducted a number of non technical interviews with a number of industry leaders in signal processing and machine learning during 2021. The questions are the same for all of the interviewees to learn from their journey. Here are the links for interviews with [Yoshua Bengio](https://signalprocessingsociety.org/newsletter/2021/08/industry-leaders-signal-processing-and-machine-learning-yoshua-bengio), [Tomas Mikolov](https://signalprocessingsociety.org/newsletter/2021/07/industry-leaders-signal-processing-and-machine-learning-tomas-mikolov), [Max Welling](https://signalprocessingsociety.org/newsletter/2022/01/industry-leaders-signal-processing-and-machine-learning-max-welling), [Xuedong Huang](https://signalprocessingsociety.org/newsletter/2021/06/industry-leaders-signal-processing-and-machine-learning-xuedong-huang), [Dong Yu](https://signalprocessingsociety.org/newsletter/2021/05/industry-leaders-signal-processing-and-machine-learning-dong-yu), [Luna Dong](https://signalprocessingsociety.org/newsletter/2021/12/industry-leaders-signal-processing-and-machine-learning-luna-dong), [Henrique Malvar](https://signalprocessingsociety.org/newsletter/2021/10/industry-leaders-signal-processing-and-machine-learning-henrique-malvar) and [Greg Mori](https://signalprocessingsociety.org/newsletter/2021/09/industry-leaders-signal-processing-and-machine-learning-greg-mori).  
**[2021](){: .btn--research}** Elevated to [IEEE](https://www.ieee.org/) Senior Member.  
**[2021](){: .btn--research}** "NICE: Neural Image Commenting with Empathy" will appear at [EMNLP 2021](https://2021.emnlp.org/).  
**[2021](){: .btn--research}** Gave a talk at [Facebook AI](https://ai.facebook.com/) about "Are Neuro-Symbolic Representations Helpful?".  
**[2021](){: .btn--research}** "Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization" will appear at [NAACL 2021](https://2021.naacl.org/).    
**[2021](){: .btn--research}** Will be serving as Associate Editor for [IEEE Signal Processing Magazine Newsletter](https://signalprocessingsociety.org/newsletter).  
**[2021](){: .btn--research}** "Compositional Processing Emerges in Neural Networks Solving Math Problems" will appear at [CogSci 2021](https://cognitivesciencesociety.org/cogsci-2021/).  
**[2021](){: .btn--research}** "Structural Biases for Improving Transformers on Translation into Morphologically Rich Languages" will appear at [LoResMT 2021](https://aclanthology.org/2021.mtsummit-loresmt.0/).  
**[2020](){: .btn--research}** "Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language" has been released as a technical report to [arxiv](https://arxiv.org/abs/2011.09530).  
**[2020](){: .btn--research}** Are the tasks/datasets that machine learning researchers use for natural language reasoning grounded in vision (visual question answering) actually measure the *reasoning* capability of the models? Or they are more of a competition about who has a better vision backbone (*perception*) that might be publicly available for others or not? Our [recent work](https://arxiv.org/pdf/2006.11524.pdf) proposing a Neuro-Symbolic approach that disentangles reasoning from perception to address this issue has been accepted at [ICML 2020](https://icml.cc/Conferences/2020).  
**[2020](){: .btn--research}** [My interview with IEEE Signal Processing Newsletter](https://signalprocessingsociety.org/newsletter/2020/09/series-highlight-young-professionals-signal-processing-dr-hamid-palangi).  
**[2020](){: .btn--research}** Leveraging Neuro-Symbolic representations to solve math problems helps us to better understand neural models and impose necessary discrete inductive biases into them. What are the necessary ingredients for these types of structures for being efficient in these reasoning tasks? In our [recent effort](https://arxiv.org/pdf/1910.02339.pdf) we propose an approach that will be presented at [ICML 2020](https://icml.cc/Conferences/2020).  
**[2020](){: .btn--research}** Will be serving as Area Chair for Multimodality track at [ACL 2020](https://acl2020.org/).  
**[2020](){: .btn--research}** How can we leverage the large number of image-text pairs available on the web to mimic the way people improve their scene and language understanding through weak supervision? Our work on large scale Vision and Language Pretraining [VLP](https://arxiv.org/abs/1909.11059) is a step towards this direction. Two short posts related to this work are available at [MSFT Blog](https://www.microsoft.com/en-us/research/blog/expanding-scene-and-language-understanding-with-large-scale-pre-training-and-a-unified-architecture/) and [VentureBeat](https://venturebeat.com/2019/10/08/microsofts-ai-learns-to-answer-questions-about-scenes-from-image-text-pairs/). We will be presenting this work at [AAAI 2020 (spotlight)](https://aaai.org/Conferences/AAAI-20/).  
**[2020](){: .btn--research}** Will be serving as a Member of Organizing Committee of [ACL 2020](https://acl2020.org/).  
**[2020](){: .btn--research}** ??  