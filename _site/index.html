

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Welcome - Hamid Palangi</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Hamid Palangi">
<meta property="og:title" content="Welcome">


  <link rel="canonical" href="http://localhost:4000/">
  <meta property="og:url" content="http://localhost:4000/">



  <meta property="og:description" content="About me">





  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Hamid Palangi",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Hamid Palangi Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>





<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg" style="font-size:150%"><a href="http://localhost:4000/">Hamid Palangi</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/talks/">Talks/Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/interns/">Interns</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/blogs/">Blogs/Media</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/10k/">10K</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/honors/">Honors/Awards</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/code/">Code/Dataset</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/hamid_palangi_2021_b2.jpg" class="author__avatar" alt="Hamid Palangi">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Hamid Palangi</h3>
    <p class="author__bio">Senior Researcher</p>
  </div>
  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><a href="https://www.microsoft.com/en-us/research/"><i class="fab fa-fw fa-microsoft" aria-hidden="true"></i> Microsoft Research</li>
      
      
        <li><a href="https://www.washington.edu/"><i class="fas fa-university" style="color:#4b2e83"></i> University of Washington</li>
      	  
      
        <li><a href=""><i class="fa fa-fw fa-map-marker-alt" aria-hidden="true"></i> Bellevue, WA</li>
      
      
        <li><a href="https://www.linkedin.com/in/hamidpalangi"><i class="fab fa-fw fa-linkedin fa-lg" aria-hidden="true"></i> LinkedIn</a></li>
      
      
        <li><a href="https://scholar.google.ca/citations?user=B1lAghgAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap fa-lg" style="color:#dd4b39"></i> Google Scholar</a></li>
      
      
        <li><a href="https://twitter.com/hmd_palangi"><i class="fab fa-fw fa-twitter-square fa-lg" aria-hidden="true"></i> Twitter</a></li>
      
      
        <li><a href="https://www.facebook.com/hmd.palangi"><i class="fab fa-fw fa-facebook-square fa-lg" aria-hidden="true"></i> Facebook</a></li>
      
      
        <li><a href="https://github.com/hamidpalangi"><i class="fab fa-fw fa-github-square fa-lg" aria-hidden="true"></i> Github</a></li>
      
      
        <li><a href="mailto:hamidpalangi@ieee.org"><i class="fas fa-fw fa-envelope fa-lg" style="color:#3b5998" aria-hidden="true"></i> Email</a></li>
      
      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Welcome">
    <meta itemprop="description" content="About me">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Welcome
</h1>
          
        
        
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p>My mission is to contribute to building AI systems that are Robust, Safe and ideally as Data Efficient as humans<sup style="color:#b1040e;">1</sup>. I have broad interest in Deep Learning, Natural Language Processing and Language Grounding (Language+Vision).</p>

<p>Currently I work as Senior Researcher at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, Affiliate Associate Professor at the <a href="https://www.washington.edu/">University of Washington</a>, serve as an advisor for <a href="https://www.koidra.ai/">Koidra</a> and as Associate Editor for IEEE Signal Processing Magazine <a href="https://signalprocessingsociety.org/newsletter">Newsletter</a>. I have had the priviledge to be a Senior member of <a href="https://www.ieee.org/">IEEE</a>, to serve as part of organizing committee of <a href="https://acl2020.org/">ACL 2020</a> as one of the virtual infrastructure chairs, to work as a mentor at <a href="https://www.microsoft.com/en-us/ai/ai-school">Microsoft AI School</a> from 2017 to 2019 and <a href="https://www.microsoft.com/en-us/research/academic-program/microsoft-ai-residency-program/">Microsoft AI Residency Program</a> from 2019 to 2020, and to have R&amp;D collaboration with various Microsoft product teams in Microsoft Azure (image captioning, hate speech detection), Office (document recommendation), Bing (text-image retrieval) and CELA (developing an intitial NLP system to understand legal contracts).</p>

<p>I have a PhD in Electrical and Computer Engineering from the <a href="https://www.ubc.ca/">University of British Columbia</a> advised by <a href="https://scholar.google.ca/citations?user=dqsw1u8AAAAJ&amp;hl=en">Rabab Ward</a> and <a href="https://scholar.google.ca/citations?user=GQWTo4MAAAAJ&amp;hl=en">Li Deng</a> where I worked on <a href="https://arxiv.org/abs/1508.04924">Sparse Decomposition and Compressive Sensing</a> and <a href="https://arxiv.org/abs/1502.06922">Deep Sentence Representations for Web Search Engines and Information Retrieval</a> which received <a href="">IEEE Signal Processing Society Best Paper Award 2018</a>. My MSc and BSc were in Electrical Engineering and I am still an <a href="https://en.wikipedia.org/wiki/Engineer">engineer at heart</a>.</p>

<p>For general inquiries please contact me at <a href="hamidpalangi@ieee.org">hamidpalangi [at] ieee [dot] org</a>, for Microsoft related inquiries please contact me at <a href="hpalangi@microsoft.com">hpalangi [at] microsoft [dot] com</a>.<br />
For my references please refer to the <a href="https://www.linkedin.com/in/hamidpalangi">recommendations</a> section of my Linkedin profile or send me an email.</p>

<p><sup style="color:#b1040e; font-size:0.7em;">1</sup> <span style="font-size:0.7em;">It has been found in previous studies of language that a child hears or produces about 8 million words in 15 months between the ages 9 to 24 months, or around 3 million words per year reported in another study [<a href="https://www.pnas.org/content/112/41/12663">1</a>,<a href="https://www.amazon.ca/Meaningful-Differences-Everyday-Experience-American/dp/1557661979">2</a>,<a href="https://arxiv.org/pdf/2005.00955.pdf">3</a>]. Recent large scale models will need significantly more data, e.g, GPT3 consumes 499 billion words during pre-training [<a href="https://arxiv.org/pdf/2005.14165.pdf">4</a>]. </span></p>

<h2 id="news">News</h2>
<p><strong><a href="" class="btn--research">2022</a></strong> We will be giving a tutorial at <a href="https://sites.google.com/allenai.org/nsmlv-tutorial-aaai-22">AAAI 2022</a> on “Neuro-Symbolic Methods for Language and Vision”.<br />
<strong><a href="" class="btn--research">2022</a></strong> We are Organizing a workshop at <a href="https://rosecvpr22.github.io/">CVPR 2022</a> on “Robustness in Sequential Data”.<br />
<strong><a href="" class="btn--research">2022</a></strong> I have conducted a number of non technical interviews with a number of industry leaders in signal processing and machine learning during 2021. The questions are the same for all of the interviewees to learn from their journey. Here are the links for interviews with <a href="https://signalprocessingsociety.org/newsletter/2021/08/industry-leaders-signal-processing-and-machine-learning-yoshua-bengio">Yoshua Bengio</a>, <a href="https://signalprocessingsociety.org/newsletter/2021/07/industry-leaders-signal-processing-and-machine-learning-tomas-mikolov">Tomas Mikolov</a>, <a href="https://signalprocessingsociety.org/newsletter/2022/01/industry-leaders-signal-processing-and-machine-learning-max-welling">Max Welling</a>, <a href="https://signalprocessingsociety.org/newsletter/2021/06/industry-leaders-signal-processing-and-machine-learning-xuedong-huang">Xuedong Huang</a>, <a href="https://signalprocessingsociety.org/newsletter/2021/05/industry-leaders-signal-processing-and-machine-learning-dong-yu">Dong Yu</a>, <a href="https://signalprocessingsociety.org/newsletter/2021/12/industry-leaders-signal-processing-and-machine-learning-luna-dong">Luna Dong</a>, <a href="https://signalprocessingsociety.org/newsletter/2021/10/industry-leaders-signal-processing-and-machine-learning-henrique-malvar">Henrique Malvar</a> and <a href="https://signalprocessingsociety.org/newsletter/2021/09/industry-leaders-signal-processing-and-machine-learning-greg-mori">Greg Mori</a>.<br />
<strong><a href="" class="btn--research">2021</a></strong> “NICE: Neural Image Commenting with Empathy” will appear at <a href="https://aclanthology.org/2021.findings-emnlp.380.pdf">EMNLP 2021</a>.<br />
<strong><a href="" class="btn--research">2021</a></strong> “Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization” will appear at <a href="https://aclanthology.org/2021.naacl-main.381.pdf">NAACL 2021</a>.  <br />
<strong><a href="" class="btn--research">2021</a></strong> Will be serving as Associate Editor for <a href="https://signalprocessingsociety.org/newsletter">IEEE Signal Processing Magazine Newsletter</a>.<br />
<strong><a href="" class="btn--research">2021</a></strong> “Compositional Processing Emerges in Neural Networks Solving Math Problems” will appear at <a href="https://arxiv.org/abs/2105.08961">CogSci 2021</a>.<br />
<strong><a href="" class="btn--research">2021</a></strong> Will be participating in young professionals panel at <a href="https://www.2021.ieeeicassp.org/2021.ieeeicassp.org/index.html">ICASSP 2021</a> as a panelist, if you are attending ICASSP please stop by.<br />
<strong><a href="" class="btn--research">2021</a></strong> “Structural Biases for Improving Transformers on Translation into Morphologically Rich Languages” will appear at <a href="https://aclanthology.org/2021.mtsummit-loresmt.6.pdf">LoResMT 2021</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> “Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language” has been released as a technical report to <a href="https://arxiv.org/abs/2011.09530">arxiv</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> Are the tasks/datasets that machine learning researchers use for natural language reasoning grounded in vision (visual question answering) actually measure the <em>reasoning</em> capability of the models? Or they are more of a competition about who has a better vision backbone (<em>perception</em>) that might be publicly available for others or not? Our recent work proposing a Neuro-Symbolic approach that disentangles reasoning from perception to address this issue has been accepted at <a href="https://arxiv.org/pdf/2006.11524.pdf">ICML 2020</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> <a href="https://signalprocessingsociety.org/newsletter/2020/09/series-highlight-young-professionals-signal-processing-dr-hamid-palangi">My interview with IEEE Signal Processing Newsletter</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> Leveraging Neuro-Symbolic representations to solve math problems helps us to better understand neural models and impose necessary discrete inductive biases into them. What are the necessary ingredients for these types of structures for being efficient in these reasoning tasks? In our recent effort we propose an approach that will be presented at <a href="https://arxiv.org/pdf/1910.02339.pdf">ICML 2020</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> Will be serving as Area Chair for Multimodality track at <a href="https://acl2020.org/">ACL 2020</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> How can we leverage the large number of image-text pairs available on the web to mimic the way people improve their scene and language understanding through weak supervision? Our work on large scale Vision and Language Pretraining is a step towards this direction. Two short posts related to this work are available at <a href="https://www.microsoft.com/en-us/research/blog/expanding-scene-and-language-understanding-with-large-scale-pre-training-and-a-unified-architecture/">MSFT Blog</a> and <a href="https://venturebeat.com/2019/10/08/microsofts-ai-learns-to-answer-questions-about-scenes-from-image-text-pairs/">VentureBeat</a>. We will be presenting this work at <a href="https://arxiv.org/abs/1909.11059">AAAI 2020 (spotlight)</a>.<br />
<strong><a href="" class="btn--research">2020</a></strong> Will be serving as a Member of Organizing Committee of <a href="https://acl2020.org/">ACL 2020</a>.<br />
<strong><a href="" class="btn--research">2019</a></strong> “Mapping Natural-language Problems to Formal-language Solutions Using Structured Neural Representations” received <a href="https://kr2ml.github.io/2019/">best paper award at NeurIPS 2019 KR2ML workshop</a>, congrats to our intern and all the authors.<br />
<strong><a href="" class="btn--research">2019</a></strong> “Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators” has been released as a technical report to <a href="https://arxiv.org/pdf/1909.09953.pdf">arxiv</a>.<br />
<strong><a href="" class="btn--research">2019</a></strong> Our work “Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval” has been selected for <a href="https://arxiv.org/abs/1502.06922">IEEE Signal Processing Society Best Paper Award</a> for 2018 (Test of Time). It was announced during <a href="https://www.2019.ieeeicassp.org/2019.ieeeicassp.org/index.html">ICASSP 2019</a> in Brighton, UK. Congratulations to the team and wonderful collaborators!<br />
<strong><a href="" class="btn--research">2019</a></strong> “HUBERT Untangles BERT to Improve Transfer across NLP Tasks” has been released as a technical report to <a href="https://arxiv.org/abs/1910.12647">arxiv</a>.<br />
<strong><a href="" class="btn--research">2019</a></strong> I have written a short recap about <a href="https://signalprocessingsociety.org/community-involvement/speech-and-language-processing/newsletter/icassp-2019-recap">ICASSP 2019</a>.<br />
<strong><a href="" class="btn--research">2018</a></strong> Epilepsy is one of the most common neurological disorders in the world, affecting over 70 million people globally, 30 to 40 per cent of whom do not respond to medication. Our recent work published at <a href="http://dx.doi.org/10.1016/j.clinph.2018.10.010">Clinical Neurophysiology</a> proposes optimized DNN architectures to detect them.<br />
<strong><a href="" class="btn--research">2018</a></strong> Our work on perceptually de-hashing image hashes for similarity retrieval will appear at <a href="https://doi.org/10.1016/j.image.2018.06.018">Signal Processing Image Communications</a>.<br />
<strong><a href="" class="btn--research">2018</a></strong> Our work on robust detection of epileptic seizures will be presented at <a href="https://doi.org/10.1109/ICASSP.2018.8462029">ICASSP 2018</a>.<br />
<strong><a href="" class="btn--research">2018</a></strong> Our work on leveraging Neuro-Symbolic representations to design DL models for Question Answering task with higher interpretability capabilities using Paul Smolensky’s Tensor Product Representations (TPRs) got accepted at <a href="https://arxiv.org/abs/1705.08432">AAAI 2018</a> (Oral Presentation). Two short posts related to this work are available <a href="http://krieger.jhu.edu/cogsci/wp-content/uploads/sites/70/2015/10/Mind-brain_networks1.pdf">here</a> and <a href="https://jamesmccaffrey.wordpress.com/2017/05/31/a-brilliant-research-paper/">here</a>.<br />
<strong><a href="" class="btn--research">2017</a></strong> Presented a tutorial at <a href="/files/GlobalSIP2017_DL_Tutorial.pdf">IEEE GlobalSIP 2017</a> at Montreal about various Deep Learning frameworks (PyTorch, TensorFlow, MXNet, Chainer, Theano, …).<br />
<strong><a href="" class="btn--research">2017</a></strong> Our recent results leveraging Neuro-Symbolic representations in deep NLP models will be presented at <a href="http://www.interpretable-ml.org/nips2017workshop/papers/07.pdf">NIPS 2017 Explainable AI Workshop</a>.<br />
<strong><a href="" class="btn--research">2016</a></strong> I have summarized what I learned from <a href="https://sites.google.com/site/deeplearningsummerschool2016/home">Deep Learning Summer School 2016</a> at Montreal, check it out <a href="https://www.linkedin.com/pulse/what-i-learned-from-deep-learning-summer-school-2016-hamid-palangi?trk=hp-feed-article-title-like">here</a>.<br />
<strong><a href="" class="btn--research">2016</a></strong> <a href="/images/phd_defense.jpg">I defended my PhD!</a><br />
<strong><a href="" class="btn--research">2016</a></strong> Our recent work on sentence embedding for web search and IR will appear in <a href="https://www.microsoft.com/en-us/research/publication/deep-sentence-embedding-using-long-short-term-memory-networks-analysis-application-information-retrieval/">IEEE/ACM Transactions on Audio, Speech, and Language Processing</a>.<br />
<strong><a href="" class="btn--research">2016</a></strong> Our recent work proposing a deep learning approach for distributed compressive sensing will appear in IEEE Transactions on Signal Processing. Check out the <a href="https://arxiv.org/abs/1508.04924">paper</a> and a post about it at <a href="https://nuit-blanche.blogspot.com/2015/08/distributed-compressive-sensing-deep.html?utm_source=feedburner&amp;utm_medium=email&amp;utm_campaign=Feed:+blogspot/vhVI+(Nuit+Blanche)">Nuit Blanche</a>. The <a href="https://github.com/Palang2014/Distributed-Compressive-Sensing-A-Deep-Learning-Approach">codes</a> are open source, give it a try! For more information about compressive sensing check out <a href="http://dsp.rice.edu/cs/">here</a>.</p>

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

      


    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!-- <a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        <div class="page__footer-copyright">&copy; 2022 Hamid Palangi. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-217686246-1', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

